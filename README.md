# End-to-End Data Engineering Project ‚Äî PySpark, Databricks & dbt

This repository contains an **end-to-end data engineering pipeline** that integrates **PySpark**, **Databricks**, and **dbt Cloud** to design a scalable medallion architecture (Bronze ‚Üí Silver ‚Üí Gold).  
The goal is to simulate **real-world analytics engineering and data transformation workflows**, delivering **business-ready KPIs** and **incremental, production-grade data pipelines**.

---

## üß© Project Overview

This project demonstrates how to build a **modern data engineering pipeline** that ingests raw streaming data, transforms it using PySpark and dbt, and exposes key business insights through a Gold layer.  
It showcases how to handle real-world challenges like incremental loading, deduplication, and change tracking while maintaining transparency, modularity, and scalability.

### üîó Pipeline Overview

The full pipeline flow is as follows:
1. **Bronze Layer (Raw Ingestion):**  
   Data is streamed into the data lake (CSV files via PySpark Streaming) and stored as Delta tables.
2. **Silver Layer (Transformation & Cleansing):**  
   Cleaned and standardized data using dbt models (`trips.sql`), materialized incrementally with Jinja templating and logic.
3. **Gold Layer (Business KPIs):**  
   Aggregated tables with business metrics for decision-making, built with Jinja loops, conditional logic, and dbt snapshots.

---

## üñºÔ∏è Visual Architecture

![Pipeline Project Overview](images/project%20pipeline.png)

---

## üèóÔ∏è Bronze Layer ‚Äî Data Ingestion

The **Bronze Layer** captures raw streaming data from CSV files using PySpark Streaming and stores them in a Databricks data lake as Delta tables.

Key highlights:
- Streaming ingestion using `readStream()`
- Schema enforcement for consistency
- Storage in `/mnt/bronze/` path for downstream use

![Bronze Layer Ingestion](images/bronze%20layer%20ingestion.PNG)

---

## ‚öôÔ∏è PySpark Streaming & Schema Definition

PySpark Streaming enables continuous ingestion and schema validation for the incoming trip data.

![PySpark Streaming](images/pyspark%20streaming.PNG)

**Schema Example:**

![Schema](images/schema.PNG)

---

## üß† Silver Layer ‚Äî Transformation (dbt + Jinja)

The **Silver Layer** focuses on cleansing, enriching, and incrementally updating the data.

We use **dbt Cloud** (Studio & CLI) to manage models and transformations, connecting directly to Databricks.

Example model:  
`models/silver/trips.sql`
```sql
{{ 
    config(
        materialized='incremental',
        unique_key='trip_id'
    )
}}

{% set cols = ['trip_id','vehicle_id','customer_id','driver_id',
'trip_start_time','trip_end_time','distance_km','fare_amount','last_updated_timestamp'] %}

SELECT 
    {% for col in cols %}
        {{ col }}
        {% if not loop.last %},{% endif %}
    {% endfor %}
FROM {{ source("source_bronze", "trips") }}

{% if is_incremental() %}
WHERE last_updated_timestamp > (
    SELECT COALESCE(MAX(last_updated_timestamp), '1900-01-01') FROM {{ this }}
)
{% endif %}

````

This approach ensures:

* Incremental materialization (only new data processed)
* Source tracking via `source()` definitions
* Dynamic column selection via Jinja loops

<p align="center"> <img src="images/Jinja.PNG" alt="Jinja Templating" width="700"> </p>

---

## üèÖ Gold Layer ‚Äî Business KPIs & Insights

The **Gold Layer** produces three key business views designed to simulate real-world analytical dashboards.

| View                      | Purpose                | Key Metrics                                       |
| ------------------------- | ---------------------- | ------------------------------------------------- |
| `trip_revenue_kpis`       | Financial overview     | Total fare, average fare, total distance          |
| `trip_driver_performance` | Workforce productivity | Total trips, revenue per km, performance category |
| `trip_customer_trends`    | Customer retention     | Average spend, loyalty segmentation               |

Each model uses **Jinja conditions and loops** for reusable logic and **dbt snapshots** to maintain historical changes.

<p align="center"> <img src="images/dbt%20snapshots.png" alt="dbt Snapshots" width="700"> </p>

---

This approach ensures:

* Incremental materialization (only new data processed)
* Source tracking via `source()` definitions
* Dynamic column selection via Jinja loops

![Jinja Templating](images/Jinja.png)

---

## üèÖ Gold Layer ‚Äî Business KPIs & Insights

The **Gold Layer** produces three key business views designed to simulate real-world analytical dashboards.

| View                      | Purpose                | Key Metrics                                       |
| ------------------------- | ---------------------- | ------------------------------------------------- |
| `trip_revenue_kpis`       | Financial overview     | Total fare, average fare, total distance          |
| `trip_driver_performance` | Workforce productivity | Total trips, revenue per km, performance category |
| `trip_customer_trends`    | Customer retention     | Average spend, loyalty segmentation               |

Each model uses **Jinja conditions and loops** for reusable logic and **dbt snapshots** to maintain historical changes.

![dbt Snapshots](images/dbt%20snapshots.png)

---

## ‚ö° Materialization & Snapshots

Materialization strategy in dbt ensures efficient data updates:

* **Bronze & Silver:** Incremental materialization using unique keys.
* **Gold:** Snapshot-based updates for time-travel and trend analysis.

![dbt Run](images/dbt%20run.png)
![Databricks Gold Layer](images/databricks%20gold%20layer.png)

---

## üåç Real-World Impact & Learnings

### üîß Real-World Problem Solving

This pipeline reflects real-world data engineering solutions:

* **Reliable data lineage:** dbt sources and lineage graphs provide traceability.
* **Incremental & cost-efficient:** Only new data loads‚Äîideal for large streaming systems.
* **Business-ready insights:** KPIs in the Gold layer empower finance, ops, and product teams.
* **Governance & testing:** Built-in dbt tests and documentation enhance data trust.
* **Scalable design:** Follows Databricks Medallion Architecture‚Äîextendable to enterprise scale.

### üéì What I Learned

Building this project has helped me:

* Master **dbt incremental models**, **snapshots**, and **Jinja templating**.
* Understand **Databricks Delta Lake** and **PySpark Streaming** for structured streaming.
* Learn **data modeling, testing, and documentation** in dbt Cloud.
* Apply real-world engineering practices like **source control**, **versioning**, and **environment management**.

### üíº Why it Matters

This project mirrors how modern companies manage their data ecosystems‚Äîturning raw events into actionable insights with reproducible, testable, and efficient pipelines.
It demonstrates my ability to design, document, and operationalize **end-to-end data engineering workflows** using **industry-grade tools**.

---

## üß± Project Structure

```
pyspark-dbt-project/
‚îÇ
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ bronze/
‚îÇ   ‚îú‚îÄ‚îÄ silver/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ trips.sql
‚îÇ   ‚îú‚îÄ‚îÄ gold/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ trip_revenue_kpis.sql
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ trip_driver_performance.sql
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ trip_customer_trends.sql
‚îÇ
‚îú‚îÄ‚îÄ macros/
‚îÇ   ‚îî‚îÄ‚îÄ custom_utils.py
‚îÇ
‚îú‚îÄ‚îÄ seeds/
‚îú‚îÄ‚îÄ snapshots/
‚îú‚îÄ‚îÄ data/
‚îú‚îÄ‚îÄ images/
‚îÇ   ‚îú‚îÄ‚îÄ bronze_layer_ingestion.png
‚îÇ   ‚îú‚îÄ‚îÄ pyspark_streaming.png
‚îÇ   ‚îú‚îÄ‚îÄ schema.png
‚îÇ   ‚îú‚îÄ‚îÄ jinja.png
‚îÇ   ‚îú‚îÄ‚îÄ dbt_snapshots.png
‚îÇ   ‚îú‚îÄ‚îÄ dbt_run.png
‚îÇ   ‚îú‚îÄ‚îÄ databricks_gold_layer.png
‚îÇ   ‚îî‚îÄ‚îÄ pipeline_project.png
‚îÇ
‚îî‚îÄ‚îÄ README.md
```

---

## üß† Key Takeaways

* ‚úÖ **End-to-End coverage:** Raw ingestion ‚Üí Transformation ‚Üí KPIs
* üß∞ **Tools used:** PySpark, dbt Cloud, Databricks, Delta Lake
* üîÑ **Incremental processing:** Upsert logic with unique keys
* üìä **Real insights:** Revenue, driver, and customer behavior metrics
* üìà **Enterprise-ready:** Scalable medallion design with modular dbt models

---

## ü§ù Contact / Author

**Fred Kibutu (KibutuJr)** ‚Äî Project Owner & Implementer

* üíº **GitHub:** [KibutuJr](https://github.com/KibutuJr)
*  [üåê **Portfolio:**](https://kibutujr.vercel.app/)
*  [üí¨ **LinkedIn:**](https://www.linkedin.com/in/fred-kibutu/)
*  [üìß **Email:**](mailto:kibutujr@gmail.com)
* üóÇÔ∏è **Repository:** [pyspark-dbt-project](https://github.com/KibutuJr/pyspark-dbt-project.git)

---

> ‚ö° *This repository serves as a real-world blueprint for building scalable, maintainable, and business-driven data pipelines using PySpark, Databricks, and dbt Cloud.*

```

